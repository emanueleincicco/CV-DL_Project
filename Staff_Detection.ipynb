{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Staff Detection",
      "provenance": [],
      "collapsed_sections": [
        "C7nK5QOlk2bC",
        "rGEKfvuzVWtu",
        "geLSwlM3aYsf",
        "uh9yT-U8FZkI",
        "-sYu1Lud0lQ5",
        "0-_XktQn9_Bf",
        "IMzKtEwMlovG",
        "ex9y-N4H3LYG",
        "pHv7NMwtZidh",
        "Clf1oHPVZntX",
        "eiGZ11_WakxQ",
        "18u2CUpmj2Oo",
        "zxBQuJhFkMOy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7nK5QOlk2bC"
      },
      "source": [
        "# Global Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoy6gtnQ4lup"
      },
      "source": [
        "#@title GLOBAL IMPORTS\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import imutils\n",
        "import random\n",
        "import time\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from shutil import copyfile\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image  # to display images\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "import PIL.Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4H0ug6FeDBX"
      },
      "source": [
        "#@title GLOBAL PARAMS\n",
        "\n",
        "PARAMS = {\n",
        "    'GLOBAL': {\n",
        "        'aruco_folder': '/content/aruco'\n",
        "    },\n",
        "    'ARUCO_GEN': { # ArUco Generation Params\n",
        "        'out_dir_name': 'original_aruco',\n",
        "        'nr_of_aruco': 15,\n",
        "        'type_of_aruco': 'DICT_4X4_1000',\n",
        "        'aruco_width': 30,\n",
        "        'aruco_height': 30,\n",
        "        'aruco_border_size': 5 # ATT!! total dims: width=aruco_width + (2 * aruco_border_size), height=...\n",
        "    },\n",
        "    'ARUCO_TRANSF': { # Transformation Params\n",
        "        'out_dir_name': 'edited_aruco',\n",
        "        'nr_of_perspective_transfs': 3,\n",
        "        'nr_of_transformations': 5,\n",
        "        'reduct_fact_width_range': [0.40, 0.70],\n",
        "        'reduct_fact_height_range': [0.30, 0.70],\n",
        "        'range_brightness_alpha': [1, 1] , # gain (contrast control)\n",
        "        'range_brightness_beta': [-40, 100], # bias (brightness control)\n",
        "        'enable_aruco_occlusions': True,\n",
        "        'reduce_factor_occlusions': 3\n",
        "    },\n",
        "    'COCO_DATASET': { # COCO Dataset Params\n",
        "        'imgs_dir_name': '/content/coco/images'\n",
        "    },\n",
        "    'IMAGE_OVERLAY': { # Image Overlay Params\n",
        "        'dataset_path': '/content/dataset',\n",
        "        'labels_path': 'labels',\n",
        "        'imgs_path': 'images',\n",
        "        'canny_threshold1': 10,\n",
        "        'canny_threshold2': 100,\n",
        "        'nr_of_imgs_for_aruco': 20, # nr of COCO images for each ArUco image (each ArUco has 'nr_of_transformations' + 1 images)\n",
        "        'range_images_size_width': [500, 700],\n",
        "        'range_images_size_height': [500, 700],\n",
        "        'disable_grayscale_imgs': True,\n",
        "    },\n",
        "    'DRIVE': {\n",
        "        'mount_drive_dir': '/content/drive',\n",
        "        'dest_dir': 'MyDrive/TestColab',\n",
        "        'custom_db_yaml_path': 'MyDrive/TestColab/data/custom_db.yaml',\n",
        "        'coco_db_path': 'MyDrive/TestColab/2021_07_10_07_46_COCO_DB',\n",
        "        \n",
        "    },\n",
        "    'CUSTOM_DATABASE': {\n",
        "        'database_directory': '/content/splitted_dataset',\n",
        "        'perc_train': 70, # percentage of train set \n",
        "        'perc_val': 20, # percentage of val set \n",
        "        'perc_test': 10, # percentage of test set \n",
        "        'train_dir_name': 'train',\n",
        "        'val_dir_name': 'val',\n",
        "        'test_dir_name': 'test',\n",
        "\n",
        "\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGEKfvuzVWtu"
      },
      "source": [
        "# ArUco Generation in OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY0RG7ntjdAO"
      },
      "source": [
        "#@title ArUco Generation PARAMETERS\n",
        "name_of_directory = os.path.join(PARAMS['GLOBAL']['aruco_folder'], PARAMS['ARUCO_GEN']['out_dir_name'])\n",
        "nr_of_aruco = PARAMS['ARUCO_GEN']['nr_of_aruco']\n",
        "type_of_aruco = PARAMS['ARUCO_GEN']['type_of_aruco']\n",
        "aruco_width = PARAMS['ARUCO_GEN']['aruco_width'] # in number of pixels\n",
        "aruco_height = PARAMS['ARUCO_GEN']['aruco_height'] # in number of pixels\n",
        "bordersize = PARAMS['ARUCO_GEN']['aruco_border_size'] # in number of pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS78j07w4MLC"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0rzGPi-VVnw"
      },
      "source": [
        "# define names of each possible ArUco tag OpenCV supports\n",
        "ARUCO_DICT = {\n",
        "\t\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
        "\t\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
        "\t\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
        "\t\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
        "\t\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
        "\t\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
        "\t\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
        "\t\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
        "\t\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
        "\t\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
        "\t\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
        "\t\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
        "\t\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
        "\t\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
        "\t\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
        "\t\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
        "\t\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
        "\t\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
        "\t\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
        "\t\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
        "\t\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4MoXwDOVbBs",
        "outputId": "b7e7d6ab-8c4f-49f5-f5fa-e62514600d50"
      },
      "source": [
        "# create the output directory\n",
        "Path(name_of_directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# load the ArUco dictionary\n",
        "arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[type_of_aruco])\n",
        "\n",
        "# for each ArUco to create\n",
        "for arucoID in range(nr_of_aruco):\n",
        "  # allocate memory for the output ArUco tag\n",
        "  tag = np.zeros((aruco_width, aruco_height, 1), dtype=\"uint8\")\n",
        "  # draw the ArUco tag on the output image\n",
        "  cv2.aruco.drawMarker(arucoDict, arucoID, aruco_width, tag, 1)\n",
        "\n",
        "  # add white border\n",
        "  tag = cv2.copyMakeBorder(\n",
        "    tag,\n",
        "    top=bordersize,\n",
        "    bottom=bordersize,\n",
        "    left=bordersize,\n",
        "    right=bordersize,\n",
        "    borderType=cv2.BORDER_CONSTANT,\n",
        "    value=[255, 255, 255]) \n",
        "  \n",
        "  # write the generated ArUco tag to disk and then print it\n",
        "  cv2.imwrite(os.path.join(name_of_directory, f'aruco_{arucoID:02d}.jpg'), tag)\n",
        "  cv2_imshow(tag)\n",
        "  print('\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAVUlEQVR4nN3UMQoAIAxD0R/x/lfWRVoQEZcg2kkhEN9g1Tibcpi7GawAaJtpnmoXBhhvVpyIq6naiknHJDJVWzHA2mGq9mNypn/0LGa1D17A6KfV3AFM1AhbBtaGKwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7CA3C90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAUElEQVR4nO2UuwoAIAgAz/D/f7mWwJCIhiSMnBwO9PAhlb0om9xNUAGQJVNjSn9wGWrpbOFsZMlkgLF755ZRBuge7o6Sycgkiyx9HpSXXnMDMMYGWddhx8UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C028D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAT0lEQVR4nGP8z0AcYCJS3UAqZGFgYGBgYMSr5j9trKaVZ9AAIrYQvhwKnhlWCrHGDAMDA0bSG2KeQUtc/+EsGllNU8+gRcUQjBnG4VQ0AwA1awZaI5dGPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12AD0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAUUlEQVR4nN2UwQoAIAhD36L//2W7BEVgdJHQ3YTBfCiT8ab26Ptp7ADo6rGY6CgYYO4sb8wAU8q4XUaw3+N4vWQwS8eHBUXHw7hVkAFGlap5AMJfB1qQs8n6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12890>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAATUlEQVR4nGP8z0AcYCJS3UAqZGFgYGBgYMSr5j9trKaVZxDgPwMD1G8IFo2spr1nEAAttoaYZ9CiYhjEDKI8GNoxg78UGAqeYRxORTMA5y0IW8NwUH8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C129D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAATklEQVR4nN2UMQoAMAgDz9L/f9mOSobSpZQ0c0CPEyM5yzjsvSxOAGLbyTujb8FURFRRmsEk9O0FywwG6ERyeo4wFRFlBiMqDM3ET695AeP5CFvLj2RCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12D10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAT0lEQVR4nN2UQQoAIAgEx+j/X7aLp6LwkIZ5EwamZSVRfNOc3EuwAyBHRmPUUWEAe7Ps1mJhAIsALG0VCzOVEq6OP7NEdVIzOer7oPz0NQ+4DQhZzRx4gwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12ED0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAUUlEQVR4nN2UwQoAIAhDn9H//7Jdggokuqyw3YTB9hA150zl0PfSWAGwrcc10SoYoHcGYrZkMAYzkTz60maiHSWDGcV9HUXRUpihrDdjP73mBiR5CFo4Oh+GAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12F90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAUElEQVR4nN2UMQoAIAwDL+L/v6yLIBQRB4PUTA4H8QhUjbOUQ+4lWAHQlmmeapcMMP4cMi2TyYSEtdLKCMZQuZdZeZiqrTJavJzV90H9dJo7EL8GXtXnN2kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12750>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAUUlEQVR4nN2UQQoAIAgEx+j/X7ZLIISFFwvbk4eFdVBWlJha0PfS2AGQo0dzorNggLkz4LMVgzF5WMVgBCaHTZnRNy+z/FpFmG0VVICRn6p5ABZQCFra+/TaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12910>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAATElEQVR4nN2UMQoAMAjEYun/v2yXQsVBXKTozQEviIqSy0pyP8ENgISM1oyukgFuZ5dn2UwGsO2dWweZUaDZTHw4zWRcnFsHGZn0mg98uAVZ/RKIpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12B10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAUUlEQVR4nGP8z0AcYCJS3UAqZGFgYGBgYMSr5j9trKaVZ7CB/wwMyL4cCp4ZVgqRYgYRFWiRQiOraeoZhD8Y4KyhlczQ8wzOomAoeIZxOBXNAG8wCFgPn6A5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C12790>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAATUlEQVR4nGP8z0AcYCJS3UAqZGFgYGBgYMSr5j9trB5ViBewIJhoCQ4ttoaYZxgYGKBe+A8nED4aYp5B+IM+VtMpZuhjNfUVMg6nohkAU24HWMfDbm0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C1C190>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAATklEQVR4nGP8z0AcYCJS3UAqZGFgYGBgYMSr5j9trKaVZ9DAfwYGDA8OMc9g8wItraapZxixsGhpNe1jBg0gvDXEPIO/FBgKnmEcTkUzAOglBlzT7i9AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C1C210>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAAAAACpleexAAAAT0lEQVR4nN3UMQoAIAwDwET8/5frWKwiLkFipg6BckPLwF3aZe9lsQMAeOyEZrUKUxLAAnTE7Byi1VJMOvKOkmWG4TyVz2CGKTG8Gf70mgcYnQhbeVMqbwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=40x40 at 0x7FAEB7C1C390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geLSwlM3aYsf"
      },
      "source": [
        "# All ArUco Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXnCtmOkqRDI"
      },
      "source": [
        "#@title OpenCV Transformations PARAMETERS\n",
        "out_dir = os.path.join(PARAMS['GLOBAL']['aruco_folder'], PARAMS['ARUCO_TRANSF']['out_dir_name'])\n",
        "reduct_fact_width_range = PARAMS['ARUCO_TRANSF']['reduct_fact_width_range']\n",
        "reduct_fact_height_range = PARAMS['ARUCO_TRANSF']['reduct_fact_height_range']\n",
        "nr_of_transf = PARAMS['ARUCO_TRANSF']['nr_of_transformations']\n",
        "occlusions_enabled = PARAMS['ARUCO_TRANSF']['enable_aruco_occlusions']\n",
        "red_fact_occlusions = PARAMS['ARUCO_TRANSF']['reduce_factor_occlusions']\n",
        "nr_of_perspective_transfs = PARAMS['ARUCO_TRANSF']['nr_of_perspective_transfs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIF0r5-rwdym"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSnEoNNYcTMy"
      },
      "source": [
        "def perspective_transf(paper, reduct_fact_width, reduct_fact_height):\n",
        "  # ArUco width and height\n",
        "  paper_width, paper_height = paper.shape[:2]\n",
        "  \n",
        "  # set the size of the result image \n",
        "  # out_width, out_height = paper_width, paper_height #ALTERNATIVA\n",
        "  out_width, out_height = paper_width + 10, paper_height + 10 # TODO\n",
        "\n",
        "  # set the coordinates that we want to perspective transform (the coords of the whole image)\n",
        "  pts1 = np.float32([[0,0], [paper_width - 1 ,0], [paper_height - 1,paper_width - 1], [0, paper_height - 1]])\n",
        "\n",
        "  # size of the transformed image\n",
        "  new_width = round(paper_width * reduct_fact_width)\n",
        "  new_height = round(paper_height * reduct_fact_height)\n",
        "\n",
        "  # top left point\n",
        "  # tl_point_x = 0 #ALTERNATIVA\n",
        "  # tl_point_y = 0 #ALTERNATIVA\n",
        "  tl_point_x = round((out_width - paper_width)/2)\n",
        "  tl_point_y = round((out_height - paper_height)/2)\n",
        "  tl_point = [tl_point_x, tl_point_y]\n",
        "\n",
        "  # top right point\n",
        "  tr_point_x = tl_point_x + (paper_width - 1)\n",
        "  tr_point_y = tl_point_y\n",
        "  tr_point = [tr_point_x, tr_point_y]\n",
        "\n",
        "  # bottom left point\n",
        "  bl_point_x = tl_point_x + (round((paper_width - new_width) / 2)) - 1\n",
        "  bl_point_y = tl_point_y + (new_height - 1)\n",
        "  bl_point = [bl_point_x, bl_point_y]\n",
        "\n",
        "  # bottom right point\n",
        "  br_point_x = bl_point_x + (new_width - 1)\n",
        "  br_point_y = bl_point_y\n",
        "  br_point = [br_point_x, br_point_y]\n",
        "\n",
        "  # set the coordinates of the new image\n",
        "  pts2 = np.float32([tl_point, tr_point, br_point, bl_point])\n",
        "\n",
        "  # transformation matrix\n",
        "  M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "  \n",
        "  # transform the original image\n",
        "  return cv2.warpPerspective(paper, M, (out_width, out_height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpHRklTK-9n5"
      },
      "source": [
        "def make_transf(orig_aruco, aruco_name, nr_of_transf, out_dir, loop, index):\n",
        "  # create an indipendente copy of the NumPy array\n",
        "  edited_aruco = np.copy(orig_aruco)\n",
        "\n",
        "  if nr_of_transf != 0:\n",
        "    # rotation transformation\n",
        "    rotation_angle = random.randrange(0, 360)\n",
        "    edited_aruco = imutils.rotate_bound(edited_aruco, rotation_angle)\n",
        "    # print transformed image\n",
        "    plt.title(f'Rotation transformation with angle={rotation_angle}')\n",
        "    plt.imshow(edited_aruco, cmap='gray')\n",
        "    plt.show()\n",
        "    # save the edited ArUco\n",
        "    cv2.imwrite(os.path.join(out_dir, aruco_name[:-4] + '_' + f\"{index:02}\" + '.jpg'), edited_aruco)\n",
        "    index += 1\n",
        "    nr_of_transf -=1 \n",
        "\n",
        "  if nr_of_transf != 0:\n",
        "    # random enable flip vertically and horizontally \n",
        "    if bool(random.getrandbits(1)):\n",
        "      edited_aruco = cv2.flip(edited_aruco, -1)\n",
        "      # print transformed image\n",
        "      plt.title(f'Flip vertically AND horizontally transformation')\n",
        "      plt.imshow(edited_aruco, cmap='gray')\n",
        "      plt.show()\n",
        "      # save the edited ArUco\n",
        "      cv2.imwrite(os.path.join(out_dir, aruco_name[:-4] + '_' + f\"{index:02}\" + '.jpg'), edited_aruco)\n",
        "      index += 1\n",
        "      nr_of_transf -= 1     \n",
        "\n",
        "  return nr_of_transf, index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-jeRdag6xR"
      },
      "source": [
        "def make_occlusion(orig_aruco):\n",
        "  aruco_w, aruco_h = orig_aruco.shape[:2]\n",
        "  tl_point = (0, 0)\n",
        "  br_point = (aruco_w - 1, aruco_h - 1)\n",
        "\n",
        "  def cover_left_edge(orig_aruco):\n",
        "    # occlusion on left edge\n",
        "    orig_aruco = cv2.rectangle(orig_aruco, tl_point, (aruco_w // red_fact_occlusions, aruco_h), (0, 0, 0), cv2.FILLED)\n",
        "    plt.title(f'Occlusion on left edge')\n",
        "\n",
        "  def cover_right_edge(orig_aruco):\n",
        "    # occlusion on right edge\n",
        "    orig_aruco = cv2.rectangle(orig_aruco, br_point, (br_point[0] - (aruco_w // red_fact_occlusions), 0), (0, 0, 0), cv2.FILLED)\n",
        "    plt.title(f'Occlusion on right edge')\n",
        "\n",
        "  def cover_top_edge(orig_aruco):\n",
        "    # occlusion on top edge\n",
        "    orig_aruco = cv2.rectangle(orig_aruco, tl_point, (aruco_w, aruco_h // red_fact_occlusions), (0, 0, 0), cv2.FILLED)\n",
        "    plt.title(f'Occlusion on top edge')\n",
        "\n",
        "  def cover_bottom_edge(orig_aruco):\n",
        "    # occlusion on bottom edge\n",
        "    orig_aruco = cv2.rectangle(orig_aruco, br_point, (0, (aruco_h - 1) - aruco_h // red_fact_occlusions), (0, 0, 0), cv2.FILLED)\n",
        "    plt.title(f'Occlusion on bottom edge')\n",
        "\n",
        "\n",
        "  options = {\n",
        "          0 : cover_left_edge,\n",
        "          1 : cover_right_edge,\n",
        "          2 : cover_top_edge,\n",
        "          3 : cover_bottom_edge\n",
        "          } \n",
        "  \n",
        "  # print transformed image\n",
        "  options[random.randint(0, 3)](orig_aruco)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOniw8ngalTv"
      },
      "source": [
        "# create dir\n",
        "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# read all ArUco filenames\n",
        "aruco_list = [f for f in os.listdir(name_of_directory) if os.path.isfile(os.path.join(name_of_directory,f))]\n",
        "\n",
        "# for each ArUco filename\n",
        "for aruco_name in aruco_list:\n",
        "  if aruco_name != \"aruco_13.jpg\":\n",
        "    continue\n",
        "  # read the ArUco image\n",
        "  original_aruco = cv2.imread(os.path.join(name_of_directory, aruco_name), cv2.IMREAD_GRAYSCALE)\n",
        "  # ArUco width and height\n",
        "  original_width, original_height = original_aruco.shape[:2]\n",
        "  # print the original image\n",
        "  plt.imshow(original_aruco, cmap='gray')\n",
        "  plt.title(f'Original ArUco {aruco_name[-6:-4]}')\n",
        "  plt.show()\n",
        "\n",
        "  index = 0\n",
        "\n",
        "  for _ in range(nr_of_perspective_transfs):\n",
        "    reduct_fact_width = random.uniform(reduct_fact_width_range[0], reduct_fact_width_range[1])\n",
        "    reduct_fact_height = random.uniform(reduct_fact_height_range[0], reduct_fact_height_range[1])\n",
        "    # perspective transformation\n",
        "    edited_aruco = perspective_transf(original_aruco, reduct_fact_width, reduct_fact_height)\n",
        "    # print transformed image\n",
        "    plt.title(f'Perspective transformation')\n",
        "    plt.imshow(edited_aruco, cmap='gray')\n",
        "    plt.show()\n",
        "    # save the transformed ArUco\n",
        "    cv2.imwrite(os.path.join(out_dir, aruco_name[:-4] + f'_{index:02}.jpg'), edited_aruco)\n",
        "\n",
        "    index += 1\n",
        "    residual_transf = nr_of_transf - 1\n",
        "\n",
        "    while(True):\n",
        "      # make some transformations\n",
        "      residual_transf, index = make_transf(edited_aruco, aruco_name, residual_transf, out_dir, False, index)\n",
        "      if residual_transf == 0:\n",
        "        break\n",
        "\n",
        "    if occlusions_enabled:\n",
        "      occluded_aruco = np.copy(original_aruco)\n",
        "      make_occlusion(occluded_aruco)\n",
        "      # print the occluded original image\n",
        "      plt.imshow(occluded_aruco, cmap='gray')\n",
        "      plt.title(f'Occluded original ArUco {aruco_name[-6:-4]}')\n",
        "      plt.show()\n",
        "      occluded_aruco = perspective_transf(occluded_aruco, reduct_fact_width, reduct_fact_height)\n",
        "      # print transformed image\n",
        "      plt.imshow(occluded_aruco, cmap='gray')\n",
        "      plt.show()\n",
        "      # save the transformed ArUco\n",
        "      cv2.imwrite(os.path.join(out_dir, aruco_name[:-4] + f'_{index:02}.jpg'), occluded_aruco)\n",
        "      # make some transformations with occluded ArUco\n",
        "      index += 1\n",
        "      residual_transf = nr_of_transf - 1\n",
        "      while(True):\n",
        "        # make some transformations\n",
        "        residual_transf, index = make_transf(occluded_aruco, aruco_name, residual_transf, out_dir, False, index)\n",
        "        if residual_transf == 0:\n",
        "          break   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh9yT-U8FZkI"
      },
      "source": [
        "# Download COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Beea1Mc90VR"
      },
      "source": [
        "#@title Download COCO dataset PARAMETERS\n",
        "images_dir_name = PARAMS['COCO_DATASET']['imgs_dir_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sYu1Lud0lQ5"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9yWeahpr806"
      },
      "source": [
        "### Download the COCO dataset images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BCXoY6YqIX2"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAjOIz9Fr14F"
      },
      "source": [
        "### Unzip downloaded zip files and remove them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrXsG1uFEGPu"
      },
      "source": [
        "# create output dir\n",
        "Path(images_dir_name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# unzip downloaded files\n",
        "!unzip /content/train2017.zip -d \"$images_dir_name\"\n",
        "\n",
        "# remove unzipped files\n",
        "!rm /content/train2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-_XktQn9_Bf"
      },
      "source": [
        "# All ArUco Overlay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95WpGJT_4Wzb"
      },
      "source": [
        "#@title Overlay PARAMETERS\n",
        "dataset_path = PARAMS['IMAGE_OVERLAY']['dataset_path']\n",
        "labels_path = PARAMS['IMAGE_OVERLAY']['labels_path']\n",
        "imgs_path = PARAMS['IMAGE_OVERLAY']['imgs_path']\n",
        "canny_thld1 = PARAMS['IMAGE_OVERLAY']['canny_threshold1'] # first threshold for the hysteresis procedure\n",
        "canny_thld2 = PARAMS['IMAGE_OVERLAY']['canny_threshold2'] # second threshold for the hysteresis procedure\n",
        "images_dir_name = PARAMS['COCO_DATASET']['imgs_dir_name']\n",
        "nr_of_imgs_for_aruco = PARAMS['IMAGE_OVERLAY']['nr_of_imgs_for_aruco']\n",
        "imgs_width_range = PARAMS['IMAGE_OVERLAY']['range_images_size_width']\n",
        "imgs_height_range = PARAMS['IMAGE_OVERLAY']['range_images_size_height']\n",
        "disable_grayscale_imgs = PARAMS['IMAGE_OVERLAY']['disable_grayscale_imgs']\n",
        "range_brightness_alpha = PARAMS['ARUCO_TRANSF']['range_brightness_alpha']\n",
        "range_brightness_beta = PARAMS['ARUCO_TRANSF']['range_brightness_beta']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWX4r7nFO62c"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6pmWNw7BBh"
      },
      "source": [
        "# create the output dirs\n",
        "# images out dir\n",
        "out_dir_imgs = os.path.join(dataset_path, imgs_path)\n",
        "Path(out_dir_imgs).mkdir(parents=True, exist_ok=True)\n",
        "# labels out dir\n",
        "out_dir_labels = os.path.join(dataset_path, labels_path)\n",
        "Path(out_dir_labels).mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S46pWoxfeLHV"
      },
      "source": [
        "def write_label(min_x, min_y, max_x, max_y, img_filename, img, x, y, aruco_filename):\n",
        "\n",
        "  # find center point, width and height of the bounding box\n",
        "  x_center = (min_x + (max_x - min_x) / 2) + x\n",
        "  y_center = (min_y + (max_y - min_y) / 2) + y\n",
        "  width_BB = (max_x - min_x)\n",
        "  height_BB = (max_y - min_y)\n",
        "\n",
        "  # normalize box coordinates and center point\n",
        "  x_center = x_center / img.shape[1]\n",
        "  y_center = y_center / img.shape[0]\n",
        "  width_BB = width_BB / img.shape[1]\n",
        "  height_BB = height_BB / img.shape[0]\n",
        "\n",
        "  # extract ArUco filename (contains ArUco ID) from the ArUco path\n",
        "  aruco_filename = os.path.basename(aruco_filename)\n",
        "  aruco_filename = os.path.splitext(aruco_filename)[0]\n",
        "\n",
        "  # extract image filename from the image path\n",
        "  img_filename = os.path.basename(img_filename)\n",
        "  img_filename = os.path.splitext(img_filename)[0]\n",
        "  \n",
        "  # create out dir\n",
        "  out_dir_file = os.path.join(out_dir_labels, os.path.basename(aruco_filename)[:8])\n",
        "  Path(out_dir_file).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # (create and) save the label file\n",
        "  with open(os.path.join(out_dir_file, img_filename + '.txt'), 'w') as f:\n",
        "    f.write(f'{aruco_filename[-5:-3]} {x_center} {y_center} {width_BB} {height_BB}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeCrKwi3z9j_"
      },
      "source": [
        "def overlay_image_alpha(img, img_overlay, x, y, alpha_mask, img_filename, aruco_filename):\n",
        "    \"\"\"Overlay `img_overlay` onto `img` at (x, y) and blend using `alpha_mask`.\n",
        "\n",
        "    `alpha_mask` must have same HxW as `img_overlay` and values in range [0, 1].\n",
        "    \"\"\"\n",
        "    # Image ranges\n",
        "    y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n",
        "    x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n",
        "\n",
        "    # Overlay ranges\n",
        "    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n",
        "    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n",
        "\n",
        "    # Exit if nothing to do\n",
        "    if y1 >= y2 or x1 >= x2 or y1o >= y2o or x1o >= x2o:\n",
        "        return\n",
        "\n",
        "    # Blend overlay within the determined ranges\n",
        "    img_crop = img[y1:y2, x1:x2]\n",
        "    img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n",
        "    alpha = alpha_mask[y1o:y2o, x1o:x2o, np.newaxis]\n",
        "    np.set_printoptions(threshold=np.inf)\n",
        "    alpha_inv = 1.0 - alpha\n",
        "    # get the white pixels\n",
        "    indices = np.where(alpha_inv == 0)\n",
        "\n",
        "    # min x\n",
        "    x_min = np.amin(indices[1])\n",
        "    # min y\n",
        "    y_min = np.amin(indices[0])\n",
        "\n",
        "    # max x\n",
        "    x_max = np.amax(indices[1])\n",
        "    # max y\n",
        "    y_max = np.amax(indices[0])\n",
        "\n",
        "    # write the label\n",
        "    write_label(x_min, y_min, x_max, y_max, img_filename, img, x, y, aruco_filename)\n",
        "\n",
        "    img_crop[:] = alpha * img_overlay_crop + alpha_inv * img_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVXDmTLlzyP5"
      },
      "source": [
        "def overlay(img_overlay_rgba, img, img_filename, aruco_filename):\n",
        "  \n",
        "  # ArUco width and height\n",
        "  img_width, img_height = img_overlay_rgba.shape[:2]\n",
        "  \n",
        "  # overlay point (x, y)\n",
        "  x, y = random.randint(0, img.shape[1] - img_width), random.randint(0, img.shape[0] - img_height)\n",
        "\n",
        "  # crop the original image\n",
        "  img_overlay_rgba = np.repeat(img_overlay_rgba.reshape((img_width, img_height, 1)), 4, axis=2)\n",
        "\n",
        "  # find edges in the ArUco image\n",
        "  edges = cv2.Canny(img_overlay_rgba, canny_thld1, canny_thld2)\n",
        "  \n",
        "  edges = cv2.dilate(edges, None)\n",
        "  # edges = cv2.erode(edges, None)\n",
        "\n",
        "  #-- Find contours in edges, sort by area\n",
        "  contour_info = []\n",
        "  contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "  for c in contours:\n",
        "      contour_info.append((\n",
        "          c,\n",
        "          cv2.isContourConvex(c),\n",
        "          cv2.contourArea(c),\n",
        "      ))\n",
        "  contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)\n",
        "\n",
        "  # create an empty mask\n",
        "  mask = np.zeros(edges.shape)\n",
        "\n",
        "  # draw filled polygon on it corresponding to largest contour (mask is black, polygon is white)\n",
        "  for c in contour_info:\n",
        "      cv2.fillConvexPoly(mask, c[0], (255))\n",
        "      break\n",
        "\n",
        "  alpha_mask = mask / 255.0\n",
        "  img_result = img[:, :, :3].copy()\n",
        "  img_overlay = img_overlay_rgba[:, :, :3]\n",
        "\n",
        "  overlay_image_alpha(img_result, img_overlay, x, y, alpha_mask, img_filename, aruco_filename)\n",
        "\n",
        "  # show the result\n",
        "  plt.imshow(img_result)\n",
        "  plt.show()\n",
        "\n",
        "  # create out dir\n",
        "  out_dir_aruco = os.path.join(out_dir_imgs, os.path.basename(aruco_filename)[:8])\n",
        "  Path(out_dir_aruco).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # random enable brightness changes\n",
        "  if bool(random.getrandbits(1)):\n",
        "    alpha = random.randint(range_brightness_alpha[0], range_brightness_alpha[1])\n",
        "    beta = random.randint(range_brightness_beta[0], range_brightness_beta[1])\n",
        "    img_result = cv2.convertScaleAbs(img_result, alpha=alpha, beta=beta)\n",
        "    # print transformed image\n",
        "    plt.title(f'Brightness transformation with alpha={alpha} and beta={beta}')\n",
        "    plt.imshow(img_result, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "  # save the result\n",
        "  cv2.imwrite(os.path.join(out_dir_aruco, os.path.basename(img_filename)), cv2.cvtColor(img_result, cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2tyuozfQ9dX0"
      },
      "source": [
        "# read all ArUco filenames\n",
        "name_of_directory = os.path.join(PARAMS['GLOBAL']['aruco_folder'], PARAMS['ARUCO_TRANSF']['out_dir_name'])\n",
        "aruco_list = [f for f in os.listdir(name_of_directory) if os.path.isfile(os.path.join(name_of_directory,f))]\n",
        "print(f'Number of ArUco: {len(aruco_list)}')\n",
        "\n",
        "# read all COCO images filenames\n",
        "name_of_directory_imgs = os.path.join(images_dir_name, 'train2017')\n",
        "imgs_list = [f for f in os.listdir(name_of_directory_imgs) if os.path.isfile(os.path.join(name_of_directory_imgs,f))]\n",
        "\n",
        "# for each ArUco make some overlays\n",
        "for aruco_name in aruco_list:\n",
        "  # read the ArUco image and create a NumPy array\n",
        "  arucoImg = PIL.Image.open(os.path.join(name_of_directory, aruco_name))\n",
        "  aruco = np.array(arucoImg)\n",
        "  index = 0\n",
        "  # for each COCO image make the overlay\n",
        "  for image in imgs_list:\n",
        "    # open the image and create a NumPy array\n",
        "    img = PIL.Image.open(os.path.join(name_of_directory_imgs, image))\n",
        "    img_array = np.array(img)\n",
        "    img_x, img_y = img_array.shape[:2]\n",
        "\n",
        "    # remove the current image from the images list\n",
        "    imgs_list.remove(image)\n",
        "    \n",
        "    # if image width and height are not in specified range OR if the image is grayscale, continue with next image\n",
        "    if img_x < imgs_width_range[0] or img_x > imgs_width_range[1] or img_y < imgs_height_range[0] or img_y > imgs_height_range[1]:\n",
        "      continue\n",
        "    elif disable_grayscale_imgs and len(img_array.shape) < 3:\n",
        "      continue\n",
        "    else:\n",
        "      # increment number of processed imgs for current ArUco\n",
        "      index +=1\n",
        "      # if the number of processed imgs is greater than specified number, switch to next ArUco\n",
        "      if index > nr_of_imgs_for_aruco:\n",
        "        break\n",
        "      else:\n",
        "        # make the overlay\n",
        "        overlay(aruco, img_array, img.filename, arucoImg.filename)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMzKtEwMlovG"
      },
      "source": [
        "# Create splitted dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV2TgOswNvMN"
      },
      "source": [
        "#@title Splitted dataset PARAMETERS\n",
        "perc_train = PARAMS['CUSTOM_DATABASE']['perc_train']\n",
        "perc_valid = PARAMS['CUSTOM_DATABASE']['perc_val']\n",
        "perc_test = PARAMS['CUSTOM_DATABASE']['perc_test']\n",
        "db_dir = PARAMS['CUSTOM_DATABASE']['database_directory']\n",
        "train_dir = PARAMS['CUSTOM_DATABASE']['train_dir_name']\n",
        "val_dir = PARAMS['CUSTOM_DATABASE']['val_dir_name']\n",
        "test_dir = PARAMS['CUSTOM_DATABASE']['test_dir_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivpMuLTCO_KN"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9wlFeZVloFL"
      },
      "source": [
        "# create dirs\n",
        "# imgs train dir\n",
        "Path(os.path.join(db_dir, imgs_path, train_dir)).mkdir(parents=True, exist_ok=True)\n",
        "# imgs val dir\n",
        "Path(os.path.join(db_dir, imgs_path, val_dir)).mkdir(parents=True, exist_ok=True)\n",
        "# imgs test dir\n",
        "Path(os.path.join(db_dir, imgs_path, test_dir)).mkdir(parents=True, exist_ok=True)\n",
        "# labels train dir\n",
        "Path(os.path.join(db_dir, labels_path, train_dir)).mkdir(parents=True, exist_ok=True)\n",
        "# labels val dir\n",
        "Path(os.path.join(db_dir, labels_path, val_dir)).mkdir(parents=True, exist_ok=True)\n",
        "# labels test dir\n",
        "Path(os.path.join(db_dir, labels_path, test_dir)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# for each aruco dir\n",
        "for aruco_dir in os.listdir(os.path.join('/content', dataset_path, imgs_path)):\n",
        "  # read image files\n",
        "  imgs_list = [f for f in os.listdir(os.path.join('/content', dataset_path, imgs_path, aruco_dir)) if os.path.isfile(os.path.join('/content', dataset_path, imgs_path, aruco_dir, f))]\n",
        "  # nr images of the ArUco\n",
        "  nr_files = len(imgs_list)\n",
        "  # read label files\n",
        "  labels_list = [f for f in os.listdir(os.path.join('/content', dataset_path, labels_path, aruco_dir)) if os.path.isfile(os.path.join('/content', dataset_path, labels_path, aruco_dir, f))]\n",
        "\n",
        "  # nr images of train set\n",
        "  nr_train = round((perc_train * nr_files) / 100)\n",
        "  # nr of images of val set\n",
        "  nr_valid = round((perc_valid * nr_files) / 100)\n",
        "  # nr of images of test set\n",
        "  nr_test = nr_files - nr_train - nr_valid\n",
        "\n",
        "  # set of all images\n",
        "  all_set = set(imgs_list)\n",
        "  # remove extension from image filenames\n",
        "  all_set = set(x[:-4] for x in all_set) \n",
        "  # set of train images\n",
        "  train = set(random.sample(all_set, nr_train))\n",
        "  # set of val images\n",
        "  val = set(random.sample(all_set - train, nr_valid))\n",
        "  # set of test images\n",
        "  test = all_set - train - val\n",
        "\n",
        "  imgs_set = set(imgs_list)\n",
        "  labels_set = set(labels_list)\n",
        "\n",
        "  # insert each image of the ArUco in the right dir\n",
        "  for image_filename in imgs_set:\n",
        "    if image_filename[:-4] in train:\n",
        "      copyfile(os.path.join('/content', dataset_path, imgs_path, aruco_dir, image_filename), os.path.join(db_dir, imgs_path, train_dir, image_filename))\n",
        "    elif image_filename[:-4] in val:\n",
        "      copyfile(os.path.join('/content', dataset_path, imgs_path, aruco_dir, image_filename), os.path.join(db_dir, imgs_path, val_dir, image_filename))\n",
        "    elif image_filename[:-4] in test:\n",
        "      copyfile(os.path.join('/content', dataset_path, imgs_path, aruco_dir, image_filename), os.path.join(db_dir, imgs_path, test_dir, image_filename))\n",
        "    else: \n",
        "      raise ValueError(f'Image +++{image_filename[:-4]}+++ is not in train or val or test set.')\n",
        "\n",
        "  # insert each label of the ArUco in the right dir\n",
        "  for label_filename in labels_set:\n",
        "    if label_filename[:-4] in train:\n",
        "      copyfile(os.path.join('/content', dataset_path, labels_path, aruco_dir, label_filename), os.path.join(db_dir, labels_path, train_dir, label_filename))\n",
        "    elif label_filename[:-4] in val:\n",
        "      copyfile(os.path.join('/content', dataset_path, labels_path, aruco_dir, label_filename), os.path.join(db_dir, labels_path, val_dir, label_filename))\n",
        "    elif label_filename[:-4] in test:\n",
        "      copyfile(os.path.join('/content', dataset_path, labels_path, aruco_dir, label_filename), os.path.join(db_dir, labels_path, test_dir, label_filename))\n",
        "    else: \n",
        "      raise ValueError(f'Label +++{label_filename[:-4]}+++ is not in train or val or test set.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex9y-N4H3LYG"
      },
      "source": [
        "# Save dataset to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1k4aZILyVQb"
      },
      "source": [
        "#@title Google Drive PARAMETERS\n",
        "drive_mount_dir = PARAMS['DRIVE']['mount_drive_dir']\n",
        "dest_dir = PARAMS['DRIVE']['dest_dir']\n",
        "dataset_path = PARAMS['IMAGE_OVERLAY']['dataset_path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVm_rcU3b6QK"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkDoP3LA3nAo"
      },
      "source": [
        "# mount Google Drive\n",
        "drive.mount(drive_mount_dir)\n",
        "\n",
        "# set output dir\n",
        "dt = time.strftime(\"%Y_%m_%d_%H_%M_DB\")\n",
        "dest = os.path.join(drive_mount_dir, dest_dir, dt) \n",
        "\n",
        "# save to Google Drive\n",
        "shutil.copytree(db_dir, dest)\n",
        "\n",
        "# unmount Google Drive\n",
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHv7NMwtZidh"
      },
      "source": [
        "# YOLO V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLdgLaOd9lOb"
      },
      "source": [
        "#@title YOLO V3 PARAMS\n",
        "drive_mount_dir = PARAMS['DRIVE']['mount_drive_dir']\n",
        "custom_yaml_path = PARAMS['DRIVE']['custom_db_yaml_path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clf1oHPVZntX"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Clone repo and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etJ_xqrvZnKB"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov3  # clone repo\n",
        "%cd yolov3\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9AH8kJRtQd"
      },
      "source": [
        "# mount Google Drive\n",
        "drive.mount(drive_mount_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WshtKeXEa5B_"
      },
      "source": [
        "# copy custom YAML DB file\n",
        "src_path = os.path.join(drive_mount_dir, custom_yaml_path)\n",
        "dest_path = os.path.join('/content/drive/MyDrive/TestColab/', 'yolov3', 'data', 'custom_db.yaml')\n",
        "shutil.copyfile(src_path, dest_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxG9Nx7OiYzF"
      },
      "source": [
        "%mkdir /content/weights\n",
        "shutil.copyfile('/content/drive/MyDrive/TestColab/yolov3/runs/train/exp/weights/best.pt', '/content/weights/best.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiGZ11_WakxQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fLAV42oNb7M"
      },
      "source": [
        "# Weights & Biases  (optional)\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# Train YOLOv3 on custom DB\n",
        "!python train.py --img 640 --batch 14 --epochs 80 --data custom_db.yaml --cfg models/yolov3.yaml --weights /content/weights/best.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PN3Ui9Mb-0H"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "source": [
        "!python test.py --weights /content/weights/best.pt --data custom_db.yaml --img 640 --iou 0.65"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18u2CUpmj2Oo"
      },
      "source": [
        "# YOLO V5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L48IyqeCj8t6"
      },
      "source": [
        "#@title YOLO V5 PARAMS\n",
        "drive_mount_dir = PARAMS['DRIVE']['mount_drive_dir']\n",
        "custom_yaml_path = PARAMS['DRIVE']['custom_db_yaml_path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxBQuJhFkMOy"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Clone repo and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLgJV1CXkMOz"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxvwUqj5m7cw"
      },
      "source": [
        "# mount Google Drive\n",
        "drive.mount(drive_mount_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2iCT8bVkMO0"
      },
      "source": [
        "# copy custom YAML DB file\n",
        "src_path = os.path.join(drive_mount_dir, custom_yaml_path)\n",
        "dest_path = os.path.join('/content/drive/MyDrive/TestColab/', 'yolov5', 'data', 'custom_db.yaml')\n",
        "shutil.copyfile(src_path, dest_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jhDKk1axkMO0"
      },
      "source": [
        "%mkdir /content/weights\n",
        "shutil.copyfile('/content/drive/MyDrive/TestColab/yolov5/train/exp/weights/best.pt', '/content/weights/best.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV_4P27LkMO0"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxKG6F7LkMO1"
      },
      "source": [
        "# Weights & Biases (optional)\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V96Ske6NkMO1"
      },
      "source": [
        "# Train YOLOv3 on custom DB\n",
        "!python train.py --img 640 --batch 16 --epochs 200 --data custom_db.yaml --weights /content/weights/best.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJdwbo9UkMO1"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjKYhH_dkMO2"
      },
      "source": [
        "!python test.py --weights /content/weights/best.pt --data custom_db.yaml --img 640 --iou 0.65 --half"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}